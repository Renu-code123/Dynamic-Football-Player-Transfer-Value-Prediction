{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5114805f",
   "metadata": {},
   "source": [
    "# POLYNOMIAL FEATURISATION WITH K=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6e97a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric feature columns used: ['nb_in_group', 'nb_on_pitch', 'goals', 'assists', 'own_goals', 'subed_in', 'subed_out', 'yellow_cards', 'second_yellow_cards', 'direct_red_cards', 'penalty_goals', 'minutes_played', 'goals_conceded', 'clean_sheets', 'height', 'is_eu', 'days_missed', 'games_missed', 'vader_polarity', 'tb_polarity', 'foot_both', 'foot_left', 'foot_right', 'foot_unknown', 'vader_emotion_negative', 'vader_emotion_neutral', 'vader_emotion_positive', 'vader_emotion_unknown', 'tb_emotion_negative', 'tb_emotion_neutral', 'tb_emotion_positive', 'tb_emotion_unknown', 'age', 'contract_remaining_days', 'days_since_joined', 'days_since_game', 'days_since_tweet', 'game_year', 'game_month', 'game_week', 'game_weekday', 'tweet_year', 'tweet_month', 'tweet_week', 'tweet_weekday', 'competition_id_freq', 'competition_name_freq', 'team_name_freq', 'citizenship_freq', 'position_Attack', 'position_Attack - Centre-Forward', 'position_Attack - Left Winger', 'position_Attack - Right Winger', 'position_Attack - Second Striker', 'position_Defender', 'position_Defender - Centre-Back', 'position_Defender - Left-Back', 'position_Defender - Right-Back', 'position_Defender - Sweeper', 'position_Goalkeeper', 'position_Midfield', 'position_Midfield - Attacking Midfield', 'position_Midfield - Central Midfield', 'position_Midfield - Defensive Midfield', 'position_Midfield - Left Midfield', 'position_Midfield - Right Midfield', 'position_unknown', 'season_name_freq', 'injury_reason_freq']\n",
      "\n",
      "ðŸ“Š MODEL PERFORMANCE WITH POLYNOMIAL FEATURES (after dropping ID columns)\n",
      "MSE  : 0.1993762296505439\n",
      "RMSE : 0.446515654429432\n",
      "RÂ²   : 0.800726114918011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1) Load dataset\n",
    "# --------------------------------------------------\n",
    "df = pd.read_csv(\"final_preprocessed_file.csv\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2) Drop ID and name columns\n",
    "# --------------------------------------------------\n",
    "cols_to_drop = [\n",
    "    \"player_id\",\n",
    "    \"team_id\",\n",
    "    \"current_club_id\",\n",
    "    \"player_agent_id\",\n",
    "    \"player_name\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3) Choose target column (transfer value)\n",
    "# --------------------------------------------------\n",
    "target = \"value_transformed\"     # <-- Change if needed\n",
    "\n",
    "y = df[target]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4) Select numeric features only\n",
    "# --------------------------------------------------\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "numeric_cols = numeric_cols.drop(target)  # remove target from features\n",
    "\n",
    "X = df[numeric_cols]\n",
    "\n",
    "print(\"Numeric feature columns used:\", list(numeric_cols))\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5) Train/Test Split\n",
    "# --------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 6) Build Pipeline (Polynomial + Scaling + Linear Regression)\n",
    "# --------------------------------------------------\n",
    "degree_k = 1   # You can change to 3 if needed\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(degree=degree_k, include_bias=False)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"reg\", LinearRegression())\n",
    "])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 7) Fit Model\n",
    "# --------------------------------------------------\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 8) Evaluate Model\n",
    "# --------------------------------------------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nðŸ“Š MODEL PERFORMANCE WITH POLYNOMIAL FEATURES (after dropping ID columns)\")\n",
    "print(f\"MSE  : {mse}\")\n",
    "print(f\"RMSE : {rmse}\")\n",
    "print(f\"RÂ²   : {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a863062",
   "metadata": {},
   "source": [
    "# POLYNOMIAL FEATURISATION WITH K=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932ec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train shape: (1885128, 174)\n",
      "Final test shape: (471282, 174)\n",
      "\n",
      "----- RESULTS -----\n",
      "MSE : 0.15189579764459202\n",
      "RMSE: 0.3897381141800119\n",
      "RÂ²   : 0.8481821740870557\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Load dataset\n",
    "# -----------------------------------------------------\n",
    "df = pd.read_csv(\"final_preprocessed_file.csv\")\n",
    "\n",
    "# 2. Drop ID / text columns (NOT useful for transfer value)\n",
    "drop_cols = [\n",
    "    \"player_id\", \"team_id\", \"current_club_id\",\n",
    "    \"player_agent_id\", \"player_name\"\n",
    "]\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# 3. Define target and nonlinear numeric features\n",
    "target = \"value_transformed\"\n",
    "\n",
    "nonlinear_numeric_features = [\n",
    "    \"goals\", \"assists\", \"minutes_played\", \"goals_conceded\",\n",
    "    \"clean_sheets\", \"days_missed\", \"games_missed\",\n",
    "    \"vader_polarity\", \"tb_polarity\",\n",
    "    \"age\", \"contract_remaining_days\",\n",
    "    \"days_since_joined\", \"days_since_game\", \"days_since_tweet\"\n",
    "]\n",
    "\n",
    "# Only keep columns that exist\n",
    "nonlinear_numeric_features = [\n",
    "    col for col in nonlinear_numeric_features if col in df.columns\n",
    "]\n",
    "\n",
    "# All other features (categorical one-hot, frequencies, etc.)\n",
    "other_features = [\n",
    "    col for col in df.columns\n",
    "    if col not in nonlinear_numeric_features + [target]\n",
    "]\n",
    "\n",
    "X1 = df[nonlinear_numeric_features]   # polynomial block\n",
    "X2 = df[other_features]               # everything else\n",
    "y = df[target]\n",
    "\n",
    "# 4. Train-test split\n",
    "X1_train, X1_test, X2_train, X2_test, y_train, y_test = train_test_split(\n",
    "    X1, X2, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Scale nonlinear numeric part (important!)\n",
    "scaler = StandardScaler()\n",
    "X1_train_scaled = scaler.fit_transform(X1_train)\n",
    "X1_test_scaled = scaler.transform(X1_test)\n",
    "\n",
    "# 6. Polynomial expansion\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "X1_train_poly = poly.fit_transform(X1_train_scaled)\n",
    "X1_test_poly = poly.transform(X1_test_scaled)\n",
    "\n",
    "# Convert to float32 to reduce memory\n",
    "X1_train_poly = X1_train_poly.astype(\"float32\")\n",
    "X1_test_poly = X1_test_poly.astype(\"float32\")\n",
    "\n",
    "# 7. Convert *other* features to numeric + float32\n",
    "X2_train = X2_train.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "X2_test = X2_test.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "X2_train_np = X2_train.to_numpy(dtype=\"float32\")\n",
    "X2_test_np = X2_test.to_numpy(dtype=\"float32\")\n",
    "\n",
    "\n",
    "# 8. Combine polynomial and other features safely\n",
    "X_train_final = np.hstack([X1_train_poly, X2_train_np])\n",
    "X_test_final = np.hstack([X1_test_poly, X2_test_np])\n",
    "\n",
    "print(\"Final train shape:\", X_train_final.shape)\n",
    "print(\"Final test shape:\", X_test_final.shape)\n",
    "\n",
    "\n",
    "# 9. Lasso Regression\n",
    "lasso = Lasso(alpha=0.001, max_iter=15000)\n",
    "lasso.fit(X_train_final, y_train)\n",
    "\n",
    "\n",
    "# 10. Predictions\n",
    "y_pred = lasso.predict(X_test_final)\n",
    "\n",
    "\n",
    "# 11. Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n----- RESULTS -----\")\n",
    "print(\"MSE :\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"RÂ²   :\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e087d3cc",
   "metadata": {},
   "source": [
    "# SAVING THE NEWLY CREATED FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0291b55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved files:\n",
      " - poly_train.csv\n",
      " - poly_test.csv\n",
      " - other_train.csv\n",
      " - other_test.csv\n",
      " - y_train.csv\n",
      " - y_test.csv\n",
      "ðŸŽ‰ All files saved in memory-optimized format!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. SMART MEMORY OPTIMIZER\n",
    "# -----------------------------------------------------\n",
    "\n",
    "def optimize_df(df):\n",
    "    \"\"\"Downcast ints, convert floats to float16 for max memory saving.\"\"\"\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        # Downcast integers\n",
    "        if pd.api.types.is_integer_dtype(col_type):\n",
    "            df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "        \n",
    "        # Downcast floats â†’ float16\n",
    "        elif pd.api.types.is_float_dtype(col_type):\n",
    "            df[col] = df[col].astype(\"float16\")\n",
    "            \n",
    "        # Convert object columns â†’ numeric float16 (if possible)\n",
    "        elif df[col].dtype == \"object\":\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(\"float16\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. BUILD SEPARATE DATAFRAMES\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# Polynomial feature names\n",
    "poly_feature_names = poly.get_feature_names_out(nonlinear_numeric_features)\n",
    "\n",
    "# Polynomial features â†’ float16\n",
    "df_poly_train = pd.DataFrame(X1_train_poly.astype(\"float16\"), columns=poly_feature_names)\n",
    "df_poly_test  = pd.DataFrame(X1_test_poly.astype(\"float16\"),  columns=poly_feature_names)\n",
    "\n",
    "# Other features â†’ convert safely then optimize\n",
    "df_other_train = X2_train.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "df_other_test  = X2_test.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Optimize all DataFrames\n",
    "df_poly_train  = optimize_df(df_poly_train)\n",
    "df_poly_test   = optimize_df(df_poly_test)\n",
    "df_other_train = optimize_df(df_other_train)\n",
    "df_other_test  = optimize_df(df_other_test)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. SAVE AS 4 SEPARATE FEATURE FILES + 2 TARGET FILES\n",
    "# -----------------------------------------------------\n",
    "\n",
    "df_poly_train.to_csv(\"poly_train.csv\", index=False)\n",
    "df_poly_test.to_csv(\"poly_test.csv\", index=False)\n",
    "\n",
    "df_other_train.to_csv(\"other_train.csv\", index=False)\n",
    "df_other_test.to_csv(\"other_test.csv\", index=False)\n",
    "\n",
    "# Save target separate\n",
    "y_train.reset_index(drop=True).to_csv(\"y_train.csv\", index=False)\n",
    "y_test.reset_index(drop=True).to_csv(\"y_test.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved files:\")\n",
    "print(\" - poly_train.csv\")\n",
    "print(\" - poly_test.csv\")\n",
    "print(\" - other_train.csv\")\n",
    "print(\" - other_test.csv\")\n",
    "print(\" - y_train.csv\")\n",
    "print(\" - y_test.csv\")\n",
    "print(\"ðŸŽ‰ All files saved in memory-optimized format!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0716621b",
   "metadata": {},
   "source": [
    "# SAVING THE POLY_TRAIN INTO TWO SUB FILES FOR MEMORY EFIICIENCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d116f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- poly_train_part1.csv\n",
      "- poly_train_part2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_csv_into_two_rowwise(input_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    mid = len(df) // 2  # midpoint\n",
    "\n",
    "    df1 = df.iloc[:mid]\n",
    "    df2 = df.iloc[mid:]\n",
    "\n",
    "    df1.to_csv(input_file.replace(\".csv\", \"_part1.csv\"), index=False)\n",
    "    df2.to_csv(input_file.replace(\".csv\", \"_part2.csv\"), index=False)\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(f\"- {input_file.replace('.csv', '_part1.csv')}\")\n",
    "    print(f\"- {input_file.replace('.csv', '_part2.csv')}\")\n",
    "\n",
    "# Run\n",
    "split_csv_into_two_rowwise(\"poly_train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a249da",
   "metadata": {},
   "source": [
    "# VERIFYING WHETHER THE SPLIT OCCURED CORECTLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4812b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1885128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "original = pd.read_csv(\"poly_train.csv\")\n",
    "print(len(original))  # number of rows in original file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903dd732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1885128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "part1 = pd.read_csv(\"poly_train_part1.csv\")\n",
    "part2 = pd.read_csv(\"poly_train_part2.csv\")\n",
    "print(len(part1) + len(part2))  # should match len of original poly_train.csv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
